{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Formative Assignment (amended)\n",
    "\n",
    "**Deadline: 12 pm - Friday 15th of November 2024**\n",
    "\n",
    "There are 5 exercises in these assignment. Each completed exercise is awarded 7 points for a total of 35 points. In order to pass the final assigment you will need to reach at least 40 points out of 100.\n",
    "\n",
    "Please send your solutions to the Weekly Classes Office (weeklyclasses@conted.ox.ac.uk) with a signed DoA (Declaration of Authorship) form. Please send the notebook with your name appended to the file name.\n",
    "\n",
    "Key things: \n",
    "- remember to comment your code!\n",
    "- when it comes to syntax, google and numpy/pandas documentations are your friends."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Let's import the libraries we are going to use later on\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Let's set the precision for NumPy and Pandas\n",
    "np.set_printoptions(precision=3)\n",
    "pd.options.display.float_format = '{:,.2f}'.format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises on Data Structures"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Compute statistics on a Python list [7 points]\n",
    "Given the following list\n",
    "```\n",
    "l = [12, 45, 12, 999, 10, 8, 76, 20, 10, 10, 7, 70, 17]\n",
    "```\n",
    "Compute the mean, the median and the standard deviation of the values in the list, using only built-in functionalities of python (no imported libraries, no NumPy or Pandas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answers:\n",
      "Mean/Average: 99.6923076923077\n",
      "Median: 12\n",
      "Standard Deviation: 260.6044407837537\n"
     ]
    }
   ],
   "source": [
    "l = [12, 45, 12, 999, 10, 8, 76, 20, 10, 10, 7, 70, 17]\n",
    "\n",
    "# Write your solution here\n",
    "\n",
    "#///////////# \n",
    "\n",
    "print(\"Answers:\")\n",
    "\n",
    "#Calculating the MEAN (average): \n",
    "#I started by calculating the lenght of the list. \n",
    "#I decided to include the \"float\" function just to get use to it, because I believe that in many realworld scenarios there might be float values in the lists.\n",
    "# Then, calculate the sum of all the elements in the list. \n",
    "#Finally, divide the total sum by the number of elements in the list. \n",
    "\n",
    "mean = sum(l) / float(len(l))\n",
    "print(\"Mean/Average: \" +str(mean))\n",
    "\n",
    "#I found an alternative method that could be: \n",
    "\n",
    "#n = len(l) \n",
    "#get_sum = sum(l) \n",
    "#mean = get_sum / n \n",
    "#print(\"Mean: \" +str(mean))\n",
    "\n",
    "#///////////# \n",
    "\n",
    "\n",
    "#Calculating the MEDIAN:\n",
    "# I Start by defining the list of numbers and calculate the length of the list.\n",
    "# Sort the list in ascending order to arrange the elements from smallest to largest.\n",
    "# Check if the length of the list is even or odd by checking the remainder when divided by 2.\n",
    "# If the number of elements is even, find the two middle elements and calculate their average.\n",
    "# If the number of elements is odd, find the middle element in the sorted list directly.\n",
    "\n",
    "\n",
    "sorted_list = sorted(l)#sorting the list to find the median \n",
    "n = len(sorted_list)\n",
    "\n",
    "if n % 2 == 1:\n",
    "    median = sorted_list[n // 2] # odd lenght: middle element \n",
    "\n",
    "else:\n",
    "    median = (sorted_lisr[n // 2 - 1] + sorted_list[n // 2]) /2\n",
    "print(\"Median: \" + str(median))\n",
    "\n",
    "#I found an alternative method that could be: \n",
    "#n = len(l)\n",
    "#l.sort() #sorting the list to find the median \n",
    "\n",
    "#if n % 2 == 0:\n",
    "    #median1 = l[n//2]\n",
    "    #median2 = l[n//2 - 1]\n",
    "    #median = (median1 + median2)/2\n",
    "#else:\n",
    "    #median = l[n//2]\n",
    "#print(\"Median: \" + str(median))\n",
    "\n",
    "#only difference is in which condition they prioritize, odd or even.\n",
    "\n",
    "#///////////# \n",
    "\n",
    "# Calculating the STANDARD DEVIATION:\n",
    "# Start by calculating the mean of the list, as this will be used to find the variance.\n",
    "# For each element in the list, calculate the squared difference from the mean.\n",
    "# Sum all the squared differences to get the total squared deviations.\n",
    "# Divide the total squared deviations by the number of elements to get the variance.\n",
    "# Finally, take the square root of the variance to obtain the standard deviation.\n",
    "\n",
    "variance = sum((x - mean) ** 2 for x in l) / len(l)\n",
    "\n",
    "std_dev = variance ** 0.5\n",
    "print(\"Standard Deviation: \" +str(std_dev))\n",
    "\n",
    "\n",
    "\n",
    "#///////////# \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2A. Create a dictionary from a list of tuples (records) [3 points]\n",
    "\n",
    "Given the following list of tuples, each one holding a record\n",
    "```\n",
    "records = [\n",
    "    ('author', 'title', 'publication_year', 'page_count'), \n",
    "    ('J. R. R. Tolkien', 'The Fellowship of the Ring', 1954, 398),\n",
    "    ('J. K. Rowling', 'Harry Potter and the Philosopher\\'s stone', 1996, 223),\n",
    "    ('Evelyn Waugh', 'Brideshead Revisited', 1945, 402),\n",
    "    ('Philip K. Dick', 'Ubik', 1969, 202),\n",
    "    ('Thomas Pynchon', \"Gravity's Rainbow\", 1973, 760),\n",
    "    ('Stephen King', 'The Stand', 1978, 829)\n",
    "]\n",
    "```\n",
    "Convert them into a list of dictionaries, using the first tuple as keys for all the dictionaries and all the other tuples as values, one per dictionary. \n",
    "Expected result:\n",
    "\n",
    "```\n",
    "books = [{'author': 'J. R. R. Tolkien',\n",
    "  'title': 'The Fellowship of the Ring',\n",
    "  'publication_year': 1954,\n",
    "  'page_count': 398},\n",
    " {'author': 'J. K. Rowling',\n",
    "  'title': \"Harry Potter and the Philosopher's stone\",\n",
    "  'publication_year': 1996,\n",
    "  'page_count': 223},\n",
    " {'author': 'Evelyn Waugh',\n",
    "  'title': 'Brideshead Revisited',\n",
    "  'publication_year': 1945,\n",
    "  'page_count': 402},\n",
    " {'author': 'Philip K. Dick',\n",
    "  'title': 'Ubik',\n",
    "  'publication_year': 1969,\n",
    "  'page_count': 202},\n",
    " {'author': 'Thomas Pynchon',\n",
    "  'title': \"Gravity's Rainbow\",\n",
    "  'publication_year': 1973,\n",
    "  'page_count': 760},\n",
    " {'author': 'Stephen King',\n",
    "  'title': 'The Stand',\n",
    "  'publication_year': 1978,\n",
    "  'page_count': 829}]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: \n",
      "Books=  [{'author': 'J. R. R. Tolkien', 'title': 'The Fellowship of the Ring', 'publication_year': 1954, 'page_count': 398}, {'author': 'J. K. Rowling', 'title': \"Harry Potter and the Philosopher's stone\", 'publication_year': 1996, 'page_count': 223}, {'author': 'Evelyn Waugh', 'title': 'Brideshead Revisited', 'publication_year': 1945, 'page_count': 402}, {'author': 'Philip K. Dick', 'title': 'Ubik', 'publication_year': 1969, 'page_count': 202}, {'author': 'Thomas Pynchon', 'title': \"Gravity's Rainbow\", 'publication_year': 1973, 'page_count': 760}, {'author': 'Stephen King', 'title': 'The Stand', 'publication_year': 1978, 'page_count': 829}]\n"
     ]
    }
   ],
   "source": [
    "records = [\n",
    "    ('author', 'title', 'publication_year', 'page_count'), \n",
    "    ('J. R. R. Tolkien', 'The Fellowship of the Ring', 1954, 398),\n",
    "    ('J. K. Rowling', 'Harry Potter and the Philosopher\\'s stone', 1996, 223),\n",
    "    ('Evelyn Waugh', 'Brideshead Revisited', 1945, 402),\n",
    "    ('Philip K. Dick', 'Ubik', 1969, 202),\n",
    "    ('Thomas Pynchon', \"Gravity's Rainbow\", 1973, 760),\n",
    "    ('Stephen King', 'The Stand', 1978, 829)\n",
    "]\n",
    "\n",
    "## Write your solution here\n",
    "# Rememnber: A list is a data structure that is mutable and has an order sequence of elements. \n",
    "#A Tuple is a collection of python objects that are comma separated that are ordered and immutable (can't be altered).\n",
    "# Tuple use parenthesis and lists uses square brackets.  \n",
    "\n",
    "#Starting by extracting the first tuple as the keys for the dictonaries. (Remembering that 0 is equal to the first valie)\n",
    "\n",
    "keys = records[0]\n",
    "\n",
    "#Creating a list of dictonaries by combing keys with each subsequent tuple in records. \n",
    "# For each tuple in records, (meaning all the yuples after the first) pair weach key with their corresponding values, forming a dictionary. \n",
    "#Keys are basically like the column names on a list. Values are what is associated to that \"key\" (coumn name).\n",
    "#zip is a buint-in python function that combines multiple iterables elements by element. \n",
    "books = [dict(zip(keys, values)) for values in records[1:]]\n",
    "\n",
    "#Printing the results\n",
    "print(\"Answer: \")\n",
    "print(\"Books= \", books)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2B. Dictionary manipulation [4 points]\n",
    "Write a function that takes the dictionary like `books` and return the author whose book has the highest page count. \n",
    "\n",
    "Apply the function to `books` to verify that it works correctly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Answer: \n",
      "Author with the highest paage count:  Stephen King\n"
     ]
    }
   ],
   "source": [
    "## Write your solution here.\n",
    "#I staert by fdefining a function to find the author with highest page count. \n",
    "#Then, use max() with a key to find the dictionary with the highest page count.\n",
    "#lambda is a function that helps create a small, anonumous function in a single line. Very useful for simple operations. \n",
    "#The syntax for lambda is= lambda arguments: expressions  \n",
    "#Specify key=lambaa book... so that max() compares the fictionaries based on their page_count values. \n",
    "#Then, return the author of that book. \n",
    "\n",
    "def author_with_highest_page_count(books):\n",
    "    book_with_max_pages = max(books, key=lambda book: book['page_count'])\n",
    "    return book_with_max_pages['author'] \n",
    "\n",
    "#Applying the functon to get the author that has the highest page count. \n",
    "highest_page_count_author = author_with_highest_page_count(books)\n",
    "\n",
    "#Result\n",
    "print(\"Answer: \")\n",
    "print(\"Author with the highest paage count: \", highest_page_count_author)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises on Numpy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For these exercises we will work on the IRIS dataset, a very popular multivariate dataset for data analysis, first introduced by Ronald Fisher in 1936.\n",
    "\n",
    "See more about the IRIS dataset heare: https://archive.ics.uci.edu/ml/datasets/Iris\n",
    "\n",
    "The data source is the file `iris.data` retrieved from the Web. It contains the data for this example in comma separated values (CSV) format. The number of columns is 5 and the number of rows is 150. The data set is composed of 50 samples from each of three species of Iris Flower: Iris Setosa, Iris Virginica and Iris Versicolor. Four features were measured from each sample: the length and the width of the sepals and petals, in centimetres. Based on the combination of these four features, Fisher developed a linear discriminant model to distinguish the species one from each other.\n",
    "\n",
    "The variables are:\n",
    "\n",
    "    sepal_length: Sepal length, in centimeters.\n",
    "    sepal_width: Sepal width, in centimeters.\n",
    "    petal_length: Petal length, in centimeters.\n",
    "    petal_width: Petal width, in centimeters.\n",
    "\n",
    "The three categories of Irises are: 'Iris Setosa', 'Iris Versicolor', and 'Iris Virginica'. \n",
    "\n",
    "Let's first import the `iris` dataset as a 1-dimensional array of tuples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input:\n",
    "# Import iris keeping the text column intact\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "iris = np.genfromtxt(\n",
    "    url, delimiter=',', \n",
    "    names=['sepal length', 'sepal width', 'petal length', 'petal width', 'species'],\n",
    "    dtype=[np.float64, np.float64, np.float64, np.float64, 'U15']\n",
    ")\n",
    "iris"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3A. How to convert a 1d array of tuples to a 2d numpy array [4 points]\n",
    "\n",
    "Exercise: convert the `iris` 1D array to a numeric-only 2D array `iris_data` by omitting the species text field. Create a `iris_label` 1D array containing only the species text field. Keep the same indexing/order as in the original array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Write your solution here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3B. Split the IRIS dataset by Label [3 points]\n",
    "\n",
    "\n",
    "Split the dataset in `iris_data` according to the labels `iris_labels`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write your solution here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Compute statistics with Numpy [7 points]\n",
    "\n",
    "1) For each flower species compute the key statistics for `sepal width`:\n",
    "- mean\n",
    "- median\n",
    "- standard deviation\n",
    "\n",
    "Answer the following questions:\n",
    "\n",
    "    a) Which is the flower type with the largest mean value for `sepal_width`?\n",
    "    b) Which is the flower type with the smallest median value for `sepal_width`?\n",
    "    \n",
    "2) Compute the correlation matrix between `sepal_width` and `petal_length` for the three scpecies. Which is the species that shows the highest correlation among the two parameters?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compute mean, median, and standard deviation for `sepal width` here:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Compute the correlation coefficients here\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. How to create a new column from existing columns of a numpy array [7 points]\n",
    "\n",
    "Create a new column for the flower volume V in `iris`, where volume is computing according to this formula (the assumption here is that the shape of the iris flower is approximately conical):\n",
    "\n",
    "$$ Volume = \\frac{\\pi \\times Sepal Length^2 \\times Petal Length}{3}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Input\n",
    "url = 'https://archive.ics.uci.edu/ml/machine-learning-databases/iris/iris.data'\n",
    "iris_2d = np.genfromtxt(url, delimiter=',', dtype='object')\n",
    "\n",
    "# Write your solution here\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
